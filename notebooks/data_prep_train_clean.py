# -*- coding: utf-8 -*-
"""data_prep.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QR3gbVktlOavebh2Et2Ub-ajoIUDmqnm
"""

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext autoreload
# %autoreload 2
# %matplotlib inline
bs = 50 # batch size
version = 1

!pip install -Uqq fastai fastbook nbdev

from fastai import *
from fastbook import *
from fastai.vision.all import *
from fastai.vision.widgets import *

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/Nut Recognizer 2



nut_labels = [
    "raw Almonds",
    "raw Walnuts",
    "raw Cashew nut",
    "raw Pecans",
    "raw Peanut",
    "raw Pili nut",
    "raw Pistachios nut",
    "raw Hazelnuts",
    "raw Brazil nut",
    "raw Maccademia nut",
    "raw Pine nut",
    "raw Chestnut",
    "raw Hickory nut",
    "raw Ginkgo nut"
]
len(nut_labels)

images = search_images_ddg(nut_labels[0])
f"No of Images => {len(images)} -- One Image URL => {images[0]}"

doc(download_url)

dest = "Almonds-3.jpg"
download_url(images[0], dest, show_progress=False)

image = Image.open(dest)
image.to_thumb(128, 128)

data_path = "data"
if not os.path.exists(data_path):
  os.mkdir(data_path)

for nut_type in nut_labels:

  dest = f"{data_path}/{nut_type}"
  if not os.path.exists(dest):
    os.mkdir(dest)

 # try:
  #  nut_image_urls = search_images_ddg(nut_type)
  #  download_images(dest, urls = nut_image_urls)

#  except:
 #   continue

image_counts = get_image_files(data_path)
image_counts

failed = verify_images(image_counts)
failed

failed.map(Path.unlink)

doc(get_image_files)



dblock = DataBlock(
    blocks=(ImageBlock, CategoryBlock),
    get_items=get_image_files,                        # get_image_files returns a list of all images in that path recursively by default
    splitter=RandomSplitter(valid_pct=0.1, seed=42),  # getting 90-10 train-validation split
    get_y=parent_label,                               # taking the folder name as labels
    item_tfms=Resize(224))

dblock = dblock.new(item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms())
dls = dblock.dataloaders(data_path, bs = bs)
torch.save(dls, f"dataloaders/nut_dataloader_v{version}.pkl")

dls.train.show_batch(max_n=8, nrows=2)

dls.valid.show_batch(max_n=8, nrows=2)

doc(aug_transforms)

# RandomResizedCrop crops images randomly and create copies so that we don't miss out anything
# aug_transforms is used for image data augmentation
dblock = dblock.new(item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms())
dls = dblock.dataloaders(data_path)
dls.train.show_batch(max_n=8, nrows=2)

model_path = "models"

model = vision_learner(dls, resnet50, metrics=[error_rate,accuracy])

model.fine_tune(5)

model.save(f"nut-recognizer-v{version}")

model.load(f"nut-recognizer-v{version}")

interp = ClassificationInterpretation.from_learner(model)
interp.plot_confusion_matrix()

interp.plot_top_losses(12, nrows=6)

cleaner = ImageClassifierCleaner(model)
cleaner # macadamia, pine nut, pecans, pistachios

model.fine_tune(1)

for idx in cleaner.delete(): cleaner.fns[idx].unlink()                                    # delete irrelevant data
for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), f"{data_path}/{cat}") # change the directory

model.save(f"nut-recognizer-v{version}")

model.export(f"{model_path}/nut-recognizer-v{version}.pkl")

model.load(f"nut-recognizer-v{version}")

model.fine_tune(1)